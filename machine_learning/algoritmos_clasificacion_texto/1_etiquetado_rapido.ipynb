{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0b172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c39194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('Here', 'RB'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('enjoying', 'VBG'),\n",
       " ('today', 'NN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"And now Here I am enjoying today\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f63e30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "None\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "None\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "None\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "None\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "None\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets_json to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets_json.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('tagsets_json')\n",
    "for tag in ['CC', 'RB', 'PRP', 'VBP', 'VBG', 'NN']:\n",
    "    print(nltk.help.upenn_tagset(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34b536fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('permit', 'VB'),\n",
       " ('other', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('recidence', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras homonimas\n",
    "text = word_tokenize(\"they do not permit other people to get recidence permit\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48519f2f",
   "metadata": {},
   "source": [
    "## Etiquetado en Espa√±ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c7364ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"cess_esp\")\n",
    "from nltk.corpus import cess_esp as cess\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9756ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_15896\\960797250.py:5: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  uni_tagger.evaluate(cess_sents[fraction:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5482623862354762"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Etiquetado por unigramas\n",
    "cess_sents = cess.tagged_sents()\n",
    "fraction = int(len(cess_sents) * 0.9/100)\n",
    "uni_tagger = ut(cess_sents[:fraction])\n",
    "uni_tagger.evaluate(cess_sents[fraction:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44341469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yo', None),\n",
       " ('soy', None),\n",
       " ('una', 'di0fs0'),\n",
       " ('persona', None),\n",
       " ('muy', 'rg'),\n",
       " ('amable', None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_tagger.tag(word_tokenize(\"Yo soy una persona muy amable\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3358c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_15896\\1768576792.py:4: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  bi_tagger.evaluate(cess_sents[fraction+1:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1095272206303725"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento por bigramas\n",
    "fraction = int(len(cess_sents) * 90/100)\n",
    "bi_tagger = bt(cess_sents[:fraction])\n",
    "bi_tagger.evaluate(cess_sents[fraction+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eebb823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yo', 'pp1csn00'),\n",
       " ('soy', 'vsip1s0'),\n",
       " ('una', None),\n",
       " ('persona', None),\n",
       " ('muy', None),\n",
       " ('amable', None)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_tagger.tag(word_tokenize(\"Yo soy una persona muy amable\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769d256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
